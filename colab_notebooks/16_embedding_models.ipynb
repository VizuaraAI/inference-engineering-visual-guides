{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 16: Embedding Models & Cosine Similarity\n",
    "\n",
    "---\n",
    "\n",
    "## Inference Engineering Course\n",
    "\n",
    "Welcome to Notebook 16! In this notebook, we explore **embedding models** -- models that convert text into dense vector representations that capture semantic meaning.\n",
    "\n",
    "### What You Will Learn\n",
    "\n",
    "| Topic | Description |\n",
    "|-------|-------------|\n",
    "| **Text Embeddings** | Generate dense vectors from text using sentence-transformers |\n",
    "| **Cosine Similarity** | Implement and understand similarity from scratch |\n",
    "| **Semantic Search** | Build a mini search engine with embeddings |\n",
    "| **Visualization** | Project embeddings to 2D using t-SNE/UMAP |\n",
    "| **Model Comparison** | Compare different embedding models |\n",
    "| **Retrieval Precision** | Measure retrieval quality at different thresholds |\n",
    "\n",
    "### Why Embeddings Matter for Inference\n",
    "\n",
    "Embedding models are the backbone of:\n",
    "- **RAG (Retrieval-Augmented Generation)**: Finding relevant documents to augment LLM context\n",
    "- **Semantic search**: Understanding user intent, not just keywords\n",
    "- **Clustering & classification**: Organizing text at scale\n",
    "- **Deduplication**: Finding near-duplicate content\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup & Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install sentence-transformers matplotlib numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity as sklearn_cosine\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Loading an Embedding Model\n",
    "\n",
    "We will use the `all-MiniLM-L6-v2` model from sentence-transformers. This is a compact but effective model:\n",
    "\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| Parameters | ~22M |\n",
    "| Embedding dimension | 384 |\n",
    "| Max sequence length | 256 tokens |\n",
    "| Speed | Very fast (CPU-friendly) |\n",
    "| Quality | Good for general-purpose tasks |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embedding model\n",
    "print(\"Loading embedding model...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(f\"Model loaded!\")\n",
    "print(f\"Embedding dimension: {model.get_sentence_embedding_dimension()}\")\n",
    "print(f\"Max sequence length: {model.max_seq_length}\")\n",
    "\n",
    "# Test with a simple sentence\n",
    "test_embedding = model.encode(\"Hello, world!\")\n",
    "print(f\"\\nTest embedding shape: {test_embedding.shape}\")\n",
    "print(f\"First 10 values: {test_embedding[:10].round(4)}\")\n",
    "print(f\"L2 norm: {np.linalg.norm(test_embedding):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Cosine Similarity from Scratch\n",
    "\n",
    "**Cosine similarity** measures the angle between two vectors, ignoring their magnitude. It is defined as:\n",
    "\n",
    "$$\\text{cosine\\_sim}(\\mathbf{a}, \\mathbf{b}) = \\frac{\\mathbf{a} \\cdot \\mathbf{b}}{\\|\\mathbf{a}\\| \\|\\mathbf{b}\\|}$$\n",
    "\n",
    "Properties:\n",
    "- Range: [-1, 1] (for normalized embeddings: [0, 1] typically)\n",
    "- 1.0 = identical direction (same meaning)\n",
    "- 0.0 = orthogonal (unrelated)\n",
    "- -1.0 = opposite direction (opposite meaning, rare in practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between two vectors from scratch.\n",
    "    \n",
    "    Args:\n",
    "        a: First vector (1D numpy array)\n",
    "        b: Second vector (1D numpy array)\n",
    "    \n",
    "    Returns:\n",
    "        Cosine similarity score between -1 and 1\n",
    "    \"\"\"\n",
    "    # Step 1: Compute dot product\n",
    "    dot_product = np.dot(a, b)\n",
    "    \n",
    "    # Step 2: Compute magnitudes (L2 norms)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    \n",
    "    # Step 3: Divide dot product by product of magnitudes\n",
    "    if norm_a == 0 or norm_b == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "\n",
    "def cosine_similarity_batch(query: np.ndarray, corpus: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between a query and all corpus vectors.\n",
    "    Efficient vectorized implementation.\n",
    "    \"\"\"\n",
    "    # Normalize vectors\n",
    "    query_norm = query / np.linalg.norm(query)\n",
    "    corpus_norms = corpus / np.linalg.norm(corpus, axis=1, keepdims=True)\n",
    "    \n",
    "    # Dot product of normalized vectors = cosine similarity\n",
    "    return corpus_norms @ query_norm\n",
    "\n",
    "\n",
    "# Test our implementation\n",
    "sentences = [\n",
    "    \"The cat sat on the mat\",\n",
    "    \"A kitten was resting on the rug\",\n",
    "    \"The stock market crashed today\",\n",
    "    \"Financial markets experienced a downturn\",\n",
    "]\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "print(\"Pairwise Cosine Similarities (from scratch):\")\n",
    "print(\"=\" * 60)\n",
    "for i in range(len(sentences)):\n",
    "    for j in range(i + 1, len(sentences)):\n",
    "        sim = cosine_similarity(embeddings[i], embeddings[j])\n",
    "        print(f\"  [{sim:.4f}] '{sentences[i]}'\")\n",
    "        print(f\"           vs '{sentences[j]}'\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the similarity matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "\n",
    "sim_matrix = np.zeros((len(sentences), len(sentences)))\n",
    "for i in range(len(sentences)):\n",
    "    for j in range(len(sentences)):\n",
    "        sim_matrix[i, j] = cosine_similarity(embeddings[i], embeddings[j])\n",
    "\n",
    "im = ax.imshow(sim_matrix, cmap='RdYlGn', vmin=0, vmax=1, aspect='auto')\n",
    "\n",
    "# Labels\n",
    "short_labels = [s[:30] + '...' if len(s) > 30 else s for s in sentences]\n",
    "ax.set_xticks(range(len(sentences)))\n",
    "ax.set_yticks(range(len(sentences)))\n",
    "ax.set_xticklabels(short_labels, rotation=45, ha='right', fontsize=9)\n",
    "ax.set_yticklabels(short_labels, fontsize=9)\n",
    "\n",
    "# Annotate values\n",
    "for i in range(len(sentences)):\n",
    "    for j in range(len(sentences)):\n",
    "        color = 'white' if sim_matrix[i, j] > 0.6 or sim_matrix[i, j] < 0.2 else 'black'\n",
    "        ax.text(j, i, f'{sim_matrix[i, j]:.3f}', ha='center', va='center',\n",
    "                fontsize=11, fontweight='bold', color=color)\n",
    "\n",
    "plt.colorbar(im, ax=ax, shrink=0.8, label='Cosine Similarity')\n",
    "ax.set_title('Pairwise Cosine Similarity Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Building a Mini Semantic Search System\n",
    "\n",
    "Let's build a simple but functional semantic search engine. The pipeline:\n",
    "\n",
    "1. **Index**: Encode all documents into embeddings\n",
    "2. **Query**: Encode the search query\n",
    "3. **Rank**: Compute cosine similarity between query and all documents\n",
    "4. **Return**: Top-K most similar documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticSearchEngine:\n",
    "    \"\"\"\n",
    "    A mini semantic search engine using embedding models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model: SentenceTransformer):\n",
    "        self.model = model\n",
    "        self.documents = []\n",
    "        self.embeddings = None\n",
    "        self.index_time = 0\n",
    "    \n",
    "    def index(self, documents: List[str]):\n",
    "        \"\"\"Encode and store document embeddings.\"\"\"\n",
    "        self.documents = documents\n",
    "        start = time.time()\n",
    "        self.embeddings = self.model.encode(documents, show_progress_bar=False)\n",
    "        self.index_time = time.time() - start\n",
    "        print(f\"Indexed {len(documents)} documents in {self.index_time:.3f}s\")\n",
    "        print(f\"  Embedding shape: {self.embeddings.shape}\")\n",
    "        print(f\"  Memory: {self.embeddings.nbytes / 1024:.1f} KB\")\n",
    "    \n",
    "    def search(self, query: str, top_k: int = 5) -> List[Dict]:\n",
    "        \"\"\"Search for the most similar documents to the query.\"\"\"\n",
    "        start = time.time()\n",
    "        query_embedding = self.model.encode(query)\n",
    "        \n",
    "        # Compute similarities\n",
    "        similarities = cosine_similarity_batch(query_embedding, self.embeddings)\n",
    "        \n",
    "        # Get top-K indices\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "        search_time = time.time() - start\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            results.append({\n",
    "                'rank': len(results) + 1,\n",
    "                'document': self.documents[idx],\n",
    "                'score': float(similarities[idx]),\n",
    "                'index': int(idx),\n",
    "            })\n",
    "        \n",
    "        return results, search_time\n",
    "\n",
    "print(\"SemanticSearchEngine class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a document corpus\n",
    "documents = [\n",
    "    # Technology\n",
    "    \"Python is a popular programming language for data science and machine learning.\",\n",
    "    \"JavaScript is the most widely used language for web development.\",\n",
    "    \"Docker containers help deploy applications consistently across environments.\",\n",
    "    \"Kubernetes orchestrates containerized applications at scale.\",\n",
    "    \"React is a JavaScript library for building user interfaces.\",\n",
    "    \"TensorFlow and PyTorch are the leading deep learning frameworks.\",\n",
    "    \"Git is a distributed version control system for tracking code changes.\",\n",
    "    \n",
    "    # Science\n",
    "    \"Photosynthesis converts sunlight into chemical energy in plants.\",\n",
    "    \"DNA carries the genetic instructions for all living organisms.\",\n",
    "    \"The theory of relativity describes gravity as curvature of spacetime.\",\n",
    "    \"Quantum mechanics governs the behavior of particles at atomic scales.\",\n",
    "    \"Climate change is driven by increasing greenhouse gas concentrations.\",\n",
    "    \n",
    "    # Food & Cooking\n",
    "    \"Sourdough bread requires a fermented starter culture and long proofing time.\",\n",
    "    \"Sushi is a Japanese dish featuring vinegared rice with seafood.\",\n",
    "    \"Espresso is made by forcing hot water through finely ground coffee beans.\",\n",
    "    \"Thai curry combines coconut milk, curry paste, and fresh herbs.\",\n",
    "    \n",
    "    # Sports\n",
    "    \"The FIFA World Cup is the most watched sporting event globally.\",\n",
    "    \"Basketball was invented by James Naismith in 1891.\",\n",
    "    \"Marathon runners cover 26.2 miles or 42.195 kilometers.\",\n",
    "    \"Tennis Grand Slams include Wimbledon, US Open, French Open, and Australian Open.\",\n",
    "]\n",
    "\n",
    "# Build the search engine\n",
    "engine = SemanticSearchEngine(model)\n",
    "engine.index(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run search queries\n",
    "queries = [\n",
    "    \"How do I build a website?\",\n",
    "    \"What is artificial intelligence?\",\n",
    "    \"Tell me about making coffee\",\n",
    "    \"Which sport has the biggest global audience?\",\n",
    "    \"How does nature produce energy from the sun?\",\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    results, search_time = engine.search(query, top_k=3)\n",
    "    print(f\"\\nQuery: '{query}'  ({search_time*1000:.1f}ms)\")\n",
    "    print(\"-\" * 70)\n",
    "    for r in results:\n",
    "        print(f\"  [{r['score']:.4f}] {r['document']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Visualizing Embeddings in 2D\n",
    "\n",
    "High-dimensional embeddings (384D) are hard to visualize. We use **t-SNE** (t-distributed Stochastic Neighbor Embedding) to project them to 2D while preserving local structure.\n",
    "\n",
    "t-SNE properties:\n",
    "- Preserves **local** neighborhood structure\n",
    "- Points that are close in high-D remain close in 2D\n",
    "- Does NOT preserve global distances\n",
    "- Non-deterministic (different runs may look different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign categories to documents for coloring\n",
    "categories = (\n",
    "    ['Technology'] * 7 + \n",
    "    ['Science'] * 5 + \n",
    "    ['Food'] * 4 + \n",
    "    ['Sports'] * 4\n",
    ")\n",
    "\n",
    "category_colors = {\n",
    "    'Technology': '#2196F3',\n",
    "    'Science': '#4CAF50',\n",
    "    'Food': '#FF9800',\n",
    "    'Sports': '#F44336',\n",
    "}\n",
    "\n",
    "# Run t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=5, n_iter=1000)\n",
    "embeddings_2d = tsne.fit_transform(engine.embeddings)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "for cat in category_colors:\n",
    "    mask = [c == cat for c in categories]\n",
    "    indices = [i for i, m in enumerate(mask) if m]\n",
    "    ax.scatter(\n",
    "        embeddings_2d[indices, 0], \n",
    "        embeddings_2d[indices, 1],\n",
    "        c=category_colors[cat], \n",
    "        s=200, \n",
    "        alpha=0.8,\n",
    "        label=cat,\n",
    "        edgecolors='black',\n",
    "        linewidths=1,\n",
    "        zorder=5\n",
    "    )\n",
    "\n",
    "# Add labels\n",
    "for i, doc in enumerate(documents):\n",
    "    short = doc[:40] + '...' if len(doc) > 40 else doc\n",
    "    ax.annotate(\n",
    "        short, \n",
    "        (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "        fontsize=7,\n",
    "        xytext=(5, 5),\n",
    "        textcoords='offset points',\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "ax.set_title('Document Embeddings Projected to 2D (t-SNE)',\n",
    "             fontsize=15, fontweight='bold')\n",
    "ax.legend(fontsize=12, loc='upper left')\n",
    "ax.set_xlabel('t-SNE Dimension 1', fontsize=12)\n",
    "ax.set_ylabel('t-SNE Dimension 2', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"Documents from the same category cluster together!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Comparing Different Embedding Models\n",
    "\n",
    "Not all embedding models are equal. Let's compare several models on the same task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to compare (small enough for free Colab)\n",
    "model_names = [\n",
    "    'all-MiniLM-L6-v2',       # 22M params, 384 dim\n",
    "    'all-MiniLM-L12-v2',      # 33M params, 384 dim\n",
    "    'paraphrase-MiniLM-L3-v2', # 17M params, 384 dim\n",
    "]\n",
    "\n",
    "# Test pairs: (sentence_a, sentence_b, expected_similarity)\n",
    "# 'high' = should be similar, 'low' = should be dissimilar\n",
    "test_pairs = [\n",
    "    (\"A dog is playing in the park\", \"A puppy runs around the garden\", 'high'),\n",
    "    (\"The weather is sunny today\", \"It's a beautiful clear day\", 'high'),\n",
    "    (\"I love programming in Python\", \"The snake slithered through the grass\", 'low'),\n",
    "    (\"The bank approved my loan\", \"I sat by the river bank\", 'low'),\n",
    "    (\"She drives a red car\", \"The automobile is crimson colored\", 'high'),\n",
    "    (\"Neural networks learn patterns\", \"Deep learning models find structure in data\", 'high'),\n",
    "    (\"The cat sleeps on the sofa\", \"Quantum physics is complex\", 'low'),\n",
    "    (\"I need to buy groceries\", \"Shopping for food at the supermarket\", 'high'),\n",
    "]\n",
    "\n",
    "model_results = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(f\"\\nLoading {model_name}...\")\n",
    "    m = SentenceTransformer(model_name)\n",
    "    \n",
    "    # Measure encoding speed\n",
    "    start = time.time()\n",
    "    all_texts = [p[0] for p in test_pairs] + [p[1] for p in test_pairs]\n",
    "    embeddings = m.encode(all_texts)\n",
    "    encode_time = time.time() - start\n",
    "    \n",
    "    # Calculate similarities\n",
    "    similarities = []\n",
    "    for i, (s1, s2, expected) in enumerate(test_pairs):\n",
    "        emb1 = embeddings[i]\n",
    "        emb2 = embeddings[len(test_pairs) + i]\n",
    "        sim = cosine_similarity(emb1, emb2)\n",
    "        similarities.append((sim, expected))\n",
    "    \n",
    "    # Calculate quality metric: average separation between high/low pairs\n",
    "    high_sims = [s for s, e in similarities if e == 'high']\n",
    "    low_sims = [s for s, e in similarities if e == 'low']\n",
    "    separation = np.mean(high_sims) - np.mean(low_sims)\n",
    "    \n",
    "    model_results[model_name] = {\n",
    "        'similarities': similarities,\n",
    "        'encode_time': encode_time,\n",
    "        'dim': m.get_sentence_embedding_dimension(),\n",
    "        'high_avg': np.mean(high_sims),\n",
    "        'low_avg': np.mean(low_sims),\n",
    "        'separation': separation,\n",
    "    }\n",
    "    \n",
    "    print(f\"  Dim: {m.get_sentence_embedding_dimension()}, Time: {encode_time:.3f}s\")\n",
    "    print(f\"  High pairs avg: {np.mean(high_sims):.4f}, Low pairs avg: {np.mean(low_sims):.4f}\")\n",
    "    print(f\"  Separation score: {separation:.4f}\")\n",
    "\n",
    "print(\"\\nAll models loaded and compared!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot 1: Similarity distributions by model\n",
    "ax = axes[0]\n",
    "x = np.arange(len(test_pairs))\n",
    "width = 0.25\n",
    "colors = ['#2196F3', '#4CAF50', '#FF9800']\n",
    "\n",
    "for i, model_name in enumerate(model_names):\n",
    "    sims = [s for s, _ in model_results[model_name]['similarities']]\n",
    "    short_name = model_name.split('-')[0] + '-' + model_name.split('-')[-1]\n",
    "    bars = ax.bar(x + i * width, sims, width, label=short_name, \n",
    "                  color=colors[i], alpha=0.8)\n",
    "\n",
    "# Color background by expected similarity\n",
    "for i, (_, _, expected) in enumerate(test_pairs):\n",
    "    if expected == 'high':\n",
    "        ax.axvspan(i - 0.4, i + 0.9, alpha=0.05, color='green')\n",
    "    else:\n",
    "        ax.axvspan(i - 0.4, i + 0.9, alpha=0.05, color='red')\n",
    "\n",
    "ax.set_xlabel('Test Pair Index', fontsize=11)\n",
    "ax.set_ylabel('Cosine Similarity', fontsize=11)\n",
    "ax.set_title('Similarity Scores by Model', fontsize=13, fontweight='bold')\n",
    "ax.legend(fontsize=9)\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels([f'P{i+1}({e[0].upper()})' for i, (_, _, e) in enumerate(test_pairs)], fontsize=8)\n",
    "\n",
    "# Plot 2: Separation scores\n",
    "ax = axes[1]\n",
    "names = [n.replace('all-', '').replace('paraphrase-', 'para-') for n in model_names]\n",
    "separations = [model_results[m]['separation'] for m in model_names]\n",
    "bars = ax.bar(names, separations, color=colors, alpha=0.8, edgecolor='black')\n",
    "for bar, val in zip(bars, separations):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,\n",
    "           f'{val:.3f}', ha='center', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Separation Score', fontsize=11)\n",
    "ax.set_title('Similarity Separation\\n(Higher = Better)', fontsize=13, fontweight='bold')\n",
    "\n",
    "# Plot 3: Speed comparison\n",
    "ax = axes[2]\n",
    "times = [model_results[m]['encode_time'] * 1000 for m in model_names]  # Convert to ms\n",
    "bars = ax.bar(names, times, color=colors, alpha=0.8, edgecolor='black')\n",
    "for bar, val in zip(bars, times):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 1,\n",
    "           f'{val:.0f}ms', ha='center', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Encoding Time (ms)', fontsize=11)\n",
    "ax.set_title('Encoding Speed\\n(Lower = Faster)', fontsize=13, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Retrieval Precision at Different Thresholds\n",
    "\n",
    "In a real search system, you need to decide: **what similarity threshold counts as a \"match\"?**\n",
    "\n",
    "Too high -> miss relevant results (low recall)\n",
    "Too low -> include irrelevant results (low precision)\n",
    "\n",
    "Let's measure precision and recall at different thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a labeled dataset for precision/recall analysis\n",
    "# Each query has ground truth relevant document indices\n",
    "eval_queries = [\n",
    "    {\n",
    "        'query': 'machine learning frameworks',\n",
    "        'relevant': [0, 5],  # Python for ML, TensorFlow/PyTorch\n",
    "    },\n",
    "    {\n",
    "        'query': 'container orchestration deployment',\n",
    "        'relevant': [2, 3],  # Docker, Kubernetes\n",
    "    },\n",
    "    {\n",
    "        'query': 'physics and the nature of the universe',\n",
    "        'relevant': [9, 10],  # Relativity, Quantum mechanics\n",
    "    },\n",
    "    {\n",
    "        'query': 'preparing food and beverages',\n",
    "        'relevant': [12, 13, 14, 15],  # All food items\n",
    "    },\n",
    "    {\n",
    "        'query': 'competitive athletics and tournaments',\n",
    "        'relevant': [16, 17, 18, 19],  # All sports items\n",
    "    },\n",
    "]\n",
    "\n",
    "# Calculate precision@k and recall@k at different thresholds\n",
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "\n",
    "precisions_at_threshold = []\n",
    "recalls_at_threshold = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    all_precisions = []\n",
    "    all_recalls = []\n",
    "    \n",
    "    for eq in eval_queries:\n",
    "        query_emb = model.encode(eq['query'])\n",
    "        sims = cosine_similarity_batch(query_emb, engine.embeddings)\n",
    "        \n",
    "        # Documents above threshold\n",
    "        retrieved = set(np.where(sims >= threshold)[0])\n",
    "        relevant = set(eq['relevant'])\n",
    "        \n",
    "        if len(retrieved) > 0:\n",
    "            precision = len(retrieved & relevant) / len(retrieved)\n",
    "        else:\n",
    "            precision = 1.0  # No results = no false positives\n",
    "        \n",
    "        recall = len(retrieved & relevant) / len(relevant) if len(relevant) > 0 else 0\n",
    "        \n",
    "        all_precisions.append(precision)\n",
    "        all_recalls.append(recall)\n",
    "    \n",
    "    precisions_at_threshold.append(np.mean(all_precisions))\n",
    "    recalls_at_threshold.append(np.mean(all_recalls))\n",
    "\n",
    "# Plot precision-recall curve\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Precision and Recall vs Threshold\n",
    "ax = axes[0]\n",
    "ax.plot(thresholds, precisions_at_threshold, 'o-', color='#2196F3', \n",
    "        linewidth=2.5, markersize=5, label='Precision')\n",
    "ax.plot(thresholds, recalls_at_threshold, 's-', color='#F44336',\n",
    "        linewidth=2.5, markersize=5, label='Recall')\n",
    "\n",
    "# F1 score\n",
    "f1_scores = [2*p*r/(p+r) if (p+r) > 0 else 0 \n",
    "             for p, r in zip(precisions_at_threshold, recalls_at_threshold)]\n",
    "ax.plot(thresholds, f1_scores, 'D-', color='#4CAF50',\n",
    "        linewidth=2.5, markersize=5, label='F1 Score')\n",
    "\n",
    "# Best F1 threshold\n",
    "best_f1_idx = np.argmax(f1_scores)\n",
    "ax.axvline(x=thresholds[best_f1_idx], color='gray', linestyle='--', alpha=0.5,\n",
    "           label=f'Best threshold: {thresholds[best_f1_idx]:.2f}')\n",
    "\n",
    "ax.set_xlabel('Similarity Threshold', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Precision, Recall, F1 vs Threshold', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.set_ylim(-0.05, 1.05)\n",
    "\n",
    "# Right: Precision-Recall curve\n",
    "ax = axes[1]\n",
    "ax.plot(recalls_at_threshold, precisions_at_threshold, 'o-', color='#9C27B0',\n",
    "        linewidth=2.5, markersize=6)\n",
    "\n",
    "# Annotate a few points with their threshold\n",
    "for i in range(0, len(thresholds), 4):\n",
    "    ax.annotate(f't={thresholds[i]:.2f}', \n",
    "               (recalls_at_threshold[i], precisions_at_threshold[i]),\n",
    "               textcoords='offset points', xytext=(10, 5), fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Recall', fontsize=12)\n",
    "ax.set_ylabel('Precision', fontsize=12)\n",
    "ax.set_title('Precision-Recall Curve', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(-0.05, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best threshold (highest F1): {thresholds[best_f1_idx]:.2f}\")\n",
    "print(f\"  Precision: {precisions_at_threshold[best_f1_idx]:.3f}\")\n",
    "print(f\"  Recall: {recalls_at_threshold[best_f1_idx]:.3f}\")\n",
    "print(f\"  F1: {f1_scores[best_f1_idx]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Understanding Embedding Space Structure\n",
    "\n",
    "Let's analyze what the embedding space looks like -- how are vectors distributed? What does \"distance\" mean in this space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze embedding space properties\n",
    "all_embeddings = engine.embeddings\n",
    "\n",
    "# 1. Distribution of pairwise similarities\n",
    "n = len(all_embeddings)\n",
    "all_sims = []\n",
    "for i in range(n):\n",
    "    for j in range(i + 1, n):\n",
    "        all_sims.append(cosine_similarity(all_embeddings[i], all_embeddings[j]))\n",
    "\n",
    "# 2. Within-category vs between-category similarities\n",
    "within_sims = []\n",
    "between_sims = []\n",
    "for i in range(n):\n",
    "    for j in range(i + 1, n):\n",
    "        sim = cosine_similarity(all_embeddings[i], all_embeddings[j])\n",
    "        if categories[i] == categories[j]:\n",
    "            within_sims.append(sim)\n",
    "        else:\n",
    "            between_sims.append(sim)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Similarity distribution\n",
    "ax = axes[0]\n",
    "ax.hist(all_sims, bins=30, alpha=0.5, color='gray', label='All pairs', edgecolor='black')\n",
    "ax.hist(within_sims, bins=20, alpha=0.6, color='#4CAF50', label='Within category', edgecolor='black')\n",
    "ax.hist(between_sims, bins=20, alpha=0.6, color='#F44336', label='Between categories', edgecolor='black')\n",
    "\n",
    "ax.axvline(np.mean(within_sims), color='#4CAF50', linestyle='--', linewidth=2)\n",
    "ax.axvline(np.mean(between_sims), color='#F44336', linestyle='--', linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Cosine Similarity', fontsize=12)\n",
    "ax.set_ylabel('Count', fontsize=12)\n",
    "ax.set_title('Distribution of Pairwise Similarities', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "\n",
    "# Right: Average similarity by category pair\n",
    "ax = axes[1]\n",
    "unique_cats = list(category_colors.keys())\n",
    "cat_sim_matrix = np.zeros((len(unique_cats), len(unique_cats)))\n",
    "\n",
    "for ci, cat_i in enumerate(unique_cats):\n",
    "    for cj, cat_j in enumerate(unique_cats):\n",
    "        sims_ij = []\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i != j and categories[i] == cat_i and categories[j] == cat_j:\n",
    "                    sims_ij.append(cosine_similarity(all_embeddings[i], all_embeddings[j]))\n",
    "        cat_sim_matrix[ci, cj] = np.mean(sims_ij) if sims_ij else 0\n",
    "\n",
    "im = ax.imshow(cat_sim_matrix, cmap='YlOrRd', vmin=0, vmax=0.7)\n",
    "ax.set_xticks(range(len(unique_cats)))\n",
    "ax.set_yticks(range(len(unique_cats)))\n",
    "ax.set_xticklabels(unique_cats, rotation=45, ha='right')\n",
    "ax.set_yticklabels(unique_cats)\n",
    "ax.set_title('Average Similarity Between Categories', fontsize=14, fontweight='bold')\n",
    "\n",
    "for i in range(len(unique_cats)):\n",
    "    for j in range(len(unique_cats)):\n",
    "        ax.text(j, i, f'{cat_sim_matrix[i,j]:.3f}', ha='center', va='center',\n",
    "                fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.colorbar(im, ax=ax, shrink=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Within-category avg similarity: {np.mean(within_sims):.4f}\")\n",
    "print(f\"Between-category avg similarity: {np.mean(between_sims):.4f}\")\n",
    "print(f\"Separation: {np.mean(within_sims) - np.mean(between_sims):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Embedding Inference Performance\n",
    "\n",
    "For production systems, embedding speed matters. Let's benchmark throughput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark embedding throughput\n",
    "batch_sizes = [1, 4, 8, 16, 32, 64]\n",
    "test_sentences = [f\"This is test sentence number {i} for benchmarking embedding model throughput.\" \n",
    "                  for i in range(64)]\n",
    "\n",
    "throughputs = []\n",
    "latencies = []\n",
    "\n",
    "for bs in batch_sizes:\n",
    "    batch = test_sentences[:bs]\n",
    "    \n",
    "    # Warmup\n",
    "    _ = model.encode(batch)\n",
    "    \n",
    "    # Measure\n",
    "    times = []\n",
    "    for _ in range(5):\n",
    "        start = time.time()\n",
    "        _ = model.encode(batch)\n",
    "        times.append(time.time() - start)\n",
    "    \n",
    "    avg_time = np.mean(times)\n",
    "    throughput = bs / avg_time\n",
    "    latency = avg_time * 1000  # ms\n",
    "    \n",
    "    throughputs.append(throughput)\n",
    "    latencies.append(latency)\n",
    "    print(f\"Batch size {bs:>3d}: {throughput:>7.1f} sentences/s | {latency:>7.1f} ms total\")\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(batch_sizes, throughputs, 'o-', color='#2196F3', linewidth=2.5, markersize=10)\n",
    "ax.set_xlabel('Batch Size', fontsize=12)\n",
    "ax.set_ylabel('Throughput (sentences/s)', fontsize=12)\n",
    "ax.set_title('Embedding Throughput vs Batch Size', fontsize=14, fontweight='bold')\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(batch_sizes, latencies, 's-', color='#F44336', linewidth=2.5, markersize=10)\n",
    "ax.set_xlabel('Batch Size', fontsize=12)\n",
    "ax.set_ylabel('Total Latency (ms)', fontsize=12)\n",
    "ax.set_title('Total Latency vs Batch Size', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: Key Takeaways\n",
    "\n",
    "### Summary\n",
    "\n",
    "1. **Embedding models** convert text into dense vectors where semantic similarity corresponds to vector proximity.\n",
    "\n",
    "2. **Cosine similarity** is the standard metric for comparing embeddings -- it measures the angle between vectors, ignoring magnitude.\n",
    "\n",
    "3. **Model choice matters**: Different embedding models have different quality-speed tradeoffs. Larger models generally have better separation but slower inference.\n",
    "\n",
    "4. **Threshold tuning** is critical for production systems -- use precision-recall analysis to find the optimal threshold for your use case.\n",
    "\n",
    "5. **Batching improves throughput** significantly -- always batch your encoding when possible.\n",
    "\n",
    "### For Inference Engineering\n",
    "\n",
    "- Embedding inference is typically **much faster** than generative LLM inference\n",
    "- Can run efficiently on CPU for smaller models\n",
    "- Key bottleneck in RAG pipelines: optimize embedding model choice and batching\n",
    "- Consider **quantized** embedding models for production at scale\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1: Build a FAQ Bot\n",
    "Create a FAQ system where you index question-answer pairs and find the most relevant answer for a new question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: FAQ Bot\n",
    "faq_pairs = [\n",
    "    {\"q\": \"How do I reset my password?\", \"a\": \"Go to Settings > Security > Reset Password.\"},\n",
    "    {\"q\": \"What are your business hours?\", \"a\": \"We are open Monday-Friday, 9am-5pm EST.\"},\n",
    "    {\"q\": \"How can I track my order?\", \"a\": \"Check the Order Status page with your order number.\"},\n",
    "    {\"q\": \"Do you offer refunds?\", \"a\": \"Yes, within 30 days of purchase.\"},\n",
    "    {\"q\": \"How do I contact support?\", \"a\": \"Email support@example.com or call 1-800-123-4567.\"},\n",
    "]\n",
    "\n",
    "# TODO: Index the FAQ questions, then search for:\n",
    "# \"I forgot my login credentials\"\n",
    "# \"When is your store open?\"\n",
    "# \"Can I get my money back?\"\n",
    "\n",
    "print(\"Exercise 1: Build the FAQ search system!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Embedding Arithmetic\n",
    "Explore if embedding arithmetic works: king - man + woman = queen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Embedding arithmetic\n",
    "# Encode: king, man, woman, queen\n",
    "# Compute: king - man + woman\n",
    "# Check: is the result closest to queen?\n",
    "\n",
    "# TODO: Test with other analogies too:\n",
    "# Paris - France + Germany = Berlin?\n",
    "# doctor - man + woman = nurse? (or doctor?)\n",
    "\n",
    "print(\"Exercise 2: Explore embedding arithmetic!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Deduplication\n",
    "Use embedding similarity to find near-duplicate documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Deduplication\n",
    "duplicate_docs = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"A fast brown fox leaps over a sleepy dog.\",  # Near duplicate\n",
    "    \"Python is great for data science.\",\n",
    "    \"For data science, Python is excellent.\",  # Near duplicate\n",
    "    \"The weather is nice today.\",\n",
    "    \"Today the weather is pleasant.\",  # Near duplicate\n",
    "    \"I love playing basketball.\",\n",
    "    \"Machine learning transforms industries.\",\n",
    "]\n",
    "\n",
    "# TODO: Find all pairs with similarity > 0.8 (likely duplicates)\n",
    "\n",
    "print(\"Exercise 3: Find the near-duplicates!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**End of Notebook 16: Embedding Models & Cosine Similarity**\n",
    "\n",
    "Next: [Notebook 17 - Image Generation: Guidance Scale & Steps](./17_image_generation_guidance.ipynb)"
   ]
  }
 ]
}